services:
  ner-english-fast:
    build:
      args:
        - FROM_BASE_IMAGE=nvcr.io/nvidia/pytorch:${MAJOR_BRANCH}-py3
      context: .
      dockerfile: Dockerfile
    image: ner-english-fast
    shm_size: 8g
    ulimits:
      memlock: -1
      stack: 67108864
    runtime: nvidia
    ports:
      - 8888:8888
    entrypoint:
      [
        "jupyter",
        "lab",
        "--no-browser",
        "--ServerApp.ip=0.0.0.0",
        "--ServerApp.port=8888",
        "--ServerApp.allow_root=True",
        "--ServerApp.token=",
        "--ServerApp.password=",
        "--Application.log_level='CRITICAL'",
      ]
    working_dir: "/workspace"
    hostname: ner-english-fast
    networks:
      triton-server:
        ipv4_address: ${INTERACTIVE_CLIENT_IP}
    volumes:
      - type: bind
        source: workspace
        target: /workspace

  triton-server:
    build:
      args:
        - FROM_BASE_IMAGE=nvcr.io/nvidia/tritonserver:${MAJOR_BRANCH}-py3
      context: .
      dockerfile: Dockerfile
    image: ner-english-fast-triton-server
    shm_size: 8g
    ulimits:
      memlock: -1
      stack: 67108864
    runtime: nvidia
    ports:
      - 8000:8000
      - 8001:8001
      - 8002:8002
    entrypoint:
      [
        "tritonserver",
        "--model-repository=/models",
        "--allow-metrics=true",
        "--allow-gpu-metrics=true",
        "--log-verbose=0",
      ]
    hostname: triton-server
    networks:
      triton-server:
        ipv4_address: ${TRITON_SERVER_IP}
    volumes:
      - type: bind
        source: workspace/triton-models
        target: /models

networks:
  triton-server:
    driver: bridge
    ipam:
      config:
        - subnet: ${SUBNET}
