{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e6aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from flair.data import Sentence\n",
    "from flair.models.sequence_tagger_utils.bioes import get_spans_from_bio\n",
    "import tritonclient.grpc as grpcclient\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dea46d4-462c-470a-afb1-1bfadcc32c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_array(string, encoding=\"utf-8\"):\n",
    "    return np.asarray(list(bytes(string, encoding)))\n",
    "\n",
    "\n",
    "def bytes_to_string(byte_list):\n",
    "    return bytes(byte_list.tolist()).decode()\n",
    "\n",
    "\n",
    "class ClientDecoder:\n",
    "    def __init__(self, triton_server_url, model_name, model_version):\n",
    "        self.triton_client = grpcclient.InferenceServerClient(\n",
    "            url=triton_server_url, verbose=False\n",
    "        )\n",
    "\n",
    "        self.model_metadata = self.triton_client.get_model_metadata(\n",
    "            model_name=model_name, model_version=model_version\n",
    "        )\n",
    "\n",
    "        self.model_config = self.triton_client.get_model_config(\n",
    "            model_name=model_name, model_version=model_version\n",
    "        ).config\n",
    "        self.model_name = model_name\n",
    "        self.viterbi_decoder = torch.load(\n",
    "            \"/workspace/triton-models/flair-ner-english-fast-tokenization/1/viterbi_decoder.bin\"\n",
    "        )\n",
    "\n",
    "    def submit(self, sentence_bytes, device=\"cpu\"):\n",
    "        sentences = [Sentence(bytes_to_string(sentence_bytes))]\n",
    "\n",
    "        inputs = [\n",
    "            grpcclient.InferInput(\"sentence_bytes\", sentence_bytes.shape, \"INT64\"),\n",
    "        ]\n",
    "\n",
    "        inputs[0].set_data_from_numpy(sentence_bytes)\n",
    "\n",
    "        outputs = [\n",
    "            grpcclient.InferRequestedOutput(\"OUTPUT__0\"),\n",
    "            grpcclient.InferRequestedOutput(\"OUTPUT__1\"),\n",
    "            grpcclient.InferRequestedOutput(\"OUTPUT__2\"),\n",
    "        ]\n",
    "\n",
    "        response = self.triton_client.infer(self.model_name, inputs, outputs=outputs)\n",
    "\n",
    "        features = torch.tensor(response.as_numpy(\"OUTPUT__0\"), device=DEVICE)\n",
    "        sorted_lengths = torch.tensor(response.as_numpy(\"OUTPUT__1\"), device=DEVICE)\n",
    "        transitions = torch.tensor(response.as_numpy(\"OUTPUT__2\"), device=DEVICE)\n",
    "\n",
    "        embedding = (features, sorted_lengths, transitions)\n",
    "\n",
    "        predictions, all_tags = self.viterbi_decoder.decode(embedding, True, sentences)\n",
    "\n",
    "        for sentence, sentence_predictions in zip(sentences, predictions):\n",
    "            sentence_tags = [label[0] for label in sentence_predictions]\n",
    "            sentence_scores = [label[1] for label in sentence_predictions]\n",
    "            predicted_spans = get_spans_from_bio(sentence_tags, sentence_scores)\n",
    "            for predicted_span in predicted_spans:\n",
    "                span = sentence[predicted_span[0][0] : predicted_span[0][-1] + 1]\n",
    "                span.add_label(\"ner\", value=predicted_span[2], score=predicted_span[1])\n",
    "\n",
    "        dict_format = {}\n",
    "        sentence_list = []\n",
    "        for entity in sentences[0].get_spans(\"ner\"):\n",
    "            sentence_list.append(\n",
    "                {\n",
    "                    \"entity_group\": entity.tag,\n",
    "                    \"start\": entity.start_position,\n",
    "                    \"word\": entity.text,\n",
    "                    \"end\": entity.end_position,\n",
    "                    \"score\": int(entity.score * 100),\n",
    "                }\n",
    "            )\n",
    "            dict_format[sentence.text] = sentence_list\n",
    "\n",
    "        return dict_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f076749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRITON_SERVER_URL = \"172.25.4.42:8001\"\n",
    "MODEL_NAME = \"flair-ner-english-fast-ensemble\"\n",
    "MODEL_VERSION = \"1\"\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "MULTIPLIER = 32\n",
    "SAMPLE_TEXTS = open(\"strings_list.txt\", \"r\").read()\n",
    "STRING_LIST = SAMPLE_TEXTS.split(\"\\n\") * MULTIPLIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57ac56e-db66-4fd6-aff9-e8532e4548f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = [string_to_array(string) for string in STRING_LIST]\n",
    "\n",
    "embeddings = torch.load(\n",
    "    \"/workspace/triton-models/flair-ner-english-fast-tokenization/1/embeddings.bin\",\n",
    "    map_location=torch.device(DEVICE),\n",
    ")\n",
    "\n",
    "viterbi_decoder = torch.load(\n",
    "    \"/workspace/triton-models/flair-ner-english-fast-tokenization/1/viterbi_decoder.bin\",\n",
    "    map_location=torch.device(DEVICE),\n",
    ")\n",
    "\n",
    "client_decoder = ClientDecoder(TRITON_SERVER_URL, MODEL_NAME, MODEL_VERSION)\n",
    "\n",
    "sentence_bytes = [string_to_array(string) for string in STRING_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1248582e-5462-4965-a5eb-efd860daccd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004412651062011719,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Submitting sentences to flair-ner-english-fast-ensemble at 172.25.4.42:8001",
       "rate": null,
       "total": 320,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1087566b2f644488ee4eeb41e182606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Submitting sentences to flair-ner-english-fast-ensemble at 172.25.4.42:8001:   0%|          | 0/320 [00:00<?, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est_total = len(sentence_bytes)\n",
    "pbar = tqdm(\n",
    "    total=est_total,\n",
    "    desc=\"Submitting sentences to {} at {}\".format(MODEL_NAME, TRITON_SERVER_URL),\n",
    ")\n",
    "\n",
    "responses = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for sentence_byte in sentence_bytes:\n",
    "        futures = []\n",
    "        futures.append(executor.submit(client_decoder.submit, sentence_byte, DEVICE))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            infer_results = future.result()\n",
    "            responses.append(infer_results)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7829220b-57b4-4f30-97f0-627f013bc6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"With the belief that the PC one day would become a consumer device for enjoying games and multimedia , NVIDIA is founded by Jensen Huang , Chris Malachowsky and Curtis Priem .\": [\n",
      "  {\n",
      "   \"entity_group\": \"ORG\",\n",
      "   \"start\": 25,\n",
      "   \"word\": \"PC\",\n",
      "   \"end\": 27,\n",
      "   \"score\": 60\n",
      "  },\n",
      "  {\n",
      "   \"entity_group\": \"ORG\",\n",
      "   \"start\": 102,\n",
      "   \"word\": \"NVIDIA\",\n",
      "   \"end\": 108,\n",
      "   \"score\": 98\n",
      "  },\n",
      "  {\n",
      "   \"entity_group\": \"PER\",\n",
      "   \"start\": 123,\n",
      "   \"word\": \"Jensen Huang\",\n",
      "   \"end\": 135,\n",
      "   \"score\": 99\n",
      "  },\n",
      "  {\n",
      "   \"entity_group\": \"PER\",\n",
      "   \"start\": 137,\n",
      "   \"word\": \"Chris Malachowsky\",\n",
      "   \"end\": 154,\n",
      "   \"score\": 99\n",
      "  },\n",
      "  {\n",
      "   \"entity_group\": \"PER\",\n",
      "   \"start\": 159,\n",
      "   \"word\": \"Curtis Priem\",\n",
      "   \"end\": 171,\n",
      "   \"score\": 99\n",
      "  }\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(responses[0], indent=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
